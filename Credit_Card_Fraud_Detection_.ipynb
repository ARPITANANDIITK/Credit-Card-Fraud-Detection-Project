{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urhl69-mjJ3O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import itertools\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the csv file\n",
        "\n",
        "dataframe = pd.read_csv(\"./Desktop/DataFlair/credit_card_fraud_detection/creditcard.csv\")\n",
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "2IdSmVg2rpFx",
        "outputId": "b41d65d0-b44a-4c15-c1ee-642745aef9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1d788c15c3e7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dataset Preparation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'creditcard.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "cLjKP2raLisq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Information about the Dataset\n",
        "dataframe.info()"
      ],
      "metadata": {
        "id": "W7n9glCjGLvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check For Null Values\n",
        "dataframe.isnull().values.any()\n"
      ],
      "metadata": {
        "id": "ax-KA6qJGT9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe[\"Amount\"].describe()"
      ],
      "metadata": {
        "id": "zA7zp48_Gj1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_fraud = len(dataframe[dataframe.Class == 0])\n",
        "fraud = len(dataframe[dataframe.Class == 1])\n",
        "fraud_percent = (fraud / (fraud + non_fraud)) * 100\n",
        "\n",
        "print(\"Number of Genuine transactions: \", non_fraud)\n",
        "print(\"Number of Fraud transactions: \", fraud)\n",
        "print(\"Percentage of Fraud transactions: {:.4f}\".format(fraud_percent))\n"
      ],
      "metadata": {
        "id": "jzmgUI5HG05y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Visualization\n",
        "labels = [\"Genuine\", \"Fraud\"]\n",
        "count_classes = dataframe.value_counts(dataframe['Class'], sort= True)\n",
        "count_classes.plot(kind = \"bar\", rot = 0)\n",
        "plt.title(\"Visualization of Labels\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(range(2), labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vHdkkeHLG5gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Scaling\n",
        "scaler = StandardScaler()\n",
        "dataframe[\"NormalizedAmount\"] = scaler.fit_transform(dataframe[\"Amount\"].values.reshape(-1, 1))\n",
        "dataframe.drop([\"Amount\",\"Time\"], inplace= True, axis= 1)\n",
        "\n",
        "Y = dataframe[\"Class\"]\n",
        "X = dataframe.drop([\"Class\"], axis= 1)\n"
      ],
      "metadata": {
        "id": "QIdjjk-nHFM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.head()\n"
      ],
      "metadata": {
        "id": "dkQ4lcAXHSuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data for training and testing\n",
        "(train_X, test_X, train_Y, test_Y) = train_test_split(X, Y, test_size= 0.3, random_state= 42)\n",
        "\n",
        "print(\"Shape of train_X: \", train_X.shape)\n",
        "print(\"Shape of test_X: \", test_X.shape)\n"
      ],
      "metadata": {
        "id": "J9xCWpfBHUlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Random Forest and Decision Tree algoritms to our dataset"
      ],
      "metadata": {
        "id": "-vEPyGncMjm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(train_X, train_Y)\n",
        "\n",
        "predictions_dt = decision_tree.predict(test_X)\n",
        "decision_tree_score = decision_tree.score(test_X, test_Y) * 100"
      ],
      "metadata": {
        "id": "ThZ2x3CfMtsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "random_forest = RandomForestClassifier(n_estimators= 100)\n",
        "random_forest.fit(train_X, train_Y)\n",
        "\n",
        "predictions_rf = random_forest.predict(test_X)\n",
        "random_forest_score = random_forest.score(test_X, test_Y) * 100"
      ],
      "metadata": {
        "id": "H48sSscqMwWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print scores of our classifiers\n",
        "\n",
        "print(\"Random Forest Score: \", random_forest_score)\n",
        "print(\"Decision Tree Score: \", decision_tree_score)"
      ],
      "metadata": {
        "id": "ptYYoHL9M0es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the confusion matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=0)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "xSWGh0doM27M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix for Decision Trees\n",
        "confusion_matrix_dt = confusion_matrix(test_Y, predictions_dt.round())\n",
        "print(\"Confusion Matrix - Decision Tree\")\n",
        "print(confusion_matrix_dt)"
      ],
      "metadata": {
        "id": "esp6YkuxNDmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(confusion_matrix_dt, classes=[0, 1], title= \"Confusion Matrix - Decision Tree\")"
      ],
      "metadata": {
        "id": "QqowQvkDNI-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix for Random Forests\n",
        "confusion_matrix_rf = confusion_matrix(test_Y, predictions_rf.round())\n",
        "print(\"Confusion Matrix - Random Forest\")\n",
        "print(confusion_matrix_rf)"
      ],
      "metadata": {
        "id": "H5J11-abNR5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(confusion_matrix_rf, classes=[0, 1], title= \"Confusion Matrix - Random Forest\")"
      ],
      "metadata": {
        "id": "7AUZMgHdNYVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Necessary Metrics\n",
        "\n",
        "def metrics(actuals, predictions):\n",
        "    print(\"Accuracy: {:.5f}\".format(accuracy_score(actuals, predictions)))\n",
        "    print(\"Precision: {:.5f}\".format(precision_score(actuals, predictions)))\n",
        "    print(\"Recall: {:.5f}\".format(recall_score(actuals, predictions)))\n",
        "    print(\"F1-score: {:.5f}\".format(f1_score(actuals, predictions)))"
      ],
      "metadata": {
        "id": "kA-9P8qXNaE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation of Decision Tree Model\")\n",
        "print()\n",
        "metrics(test_Y, predictions_dt.round())"
      ],
      "metadata": {
        "id": "wxfxPsfTNlk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation of Random Forest Model\")\n",
        "print()\n",
        "metrics(test_Y, predictions_rf.round())"
      ],
      "metadata": {
        "id": "5ST1tToTNmhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest model works better than Decision Trees as it is more precise."
      ],
      "metadata": {
        "id": "1KHN0FbcOema"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But if we observe our dataset, it suffers a problemn of CLASS IMBALANCE.\n",
        "The non-fraud transactions are more than 99% with fraud detections constituting of 0.17%."
      ],
      "metadata": {
        "id": "rD3jiT6SOtOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this kind of distribution, if we train our model without taking care of this imbalance issues, it predicts the label with higher importance given to genuine transactions ( as there are more data about them) and obtains more accuracy."
      ],
      "metadata": {
        "id": "XQ6XRKv8Pfiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can be solved using various techniques. We will use OVERSAMPLING for this project."
      ],
      "metadata": {
        "id": "hHPxybHgP-nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing oversampling on Random Forest and Decision Trees\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X_resampled, Y_resampled = SMOTE().fit_resample(X, Y)\n",
        "print(\"Resampled shape of X: \", X_resampled.shape)\n",
        "print(\"Resampled shape of Y: \", Y_resampled.shape)\n",
        "\n",
        "value_counts = Counter(Y_resampled)\n",
        "print(value_counts)\n",
        "\n",
        "(train_X, test_X, train_Y, test_Y) = train_test_split(X_resampled, Y_resampled, test_size= 0.3, random_state= 42)"
      ],
      "metadata": {
        "id": "t-Z7BKNLQcPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Random Forest classifier on the new dataset\n",
        "\n",
        "rf_resampled = RandomForestClassifier(n_estimators = 100)\n",
        "rf_resampled.fit(train_X, train_Y)\n",
        "\n",
        "predictions_resampled = rf_resampled.predict(test_X)\n",
        "random_forest_score_resampled = rf_resampled.score(test_X, test_Y) * 100"
      ],
      "metadata": {
        "id": "IwT_pNp5Ql3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cm_resampled, classes=[0, 1], title= \"Confusion Matrix - Random Forest After Oversampling\")"
      ],
      "metadata": {
        "id": "7GXP3IpiQsil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation of Random Forest Model\")\n",
        "print()\n",
        "metrics(test_Y, predictions_resampled.round())"
      ],
      "metadata": {
        "id": "0N32dPzXQvbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, our Model performs even more better after addressing the class imbalance problem increasing the precision upto 99%."
      ],
      "metadata": {
        "id": "fV4OuD08Q0Oj"
      }
    }
  ]
}